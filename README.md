# Awesome-Large-Model-Safety
## Safety at Scale: A Comprehensive Survey of Large Model Safety

--- 

Content:

- [Vision Foundation Model Safety](#ch2)
- [Large Language Model Safety](#ch3)
- [Vision-Language Pre-training Model Safety](#ch4)
- [Vison Language Model Safety](#ch5)
- [Diffusion Models Safety](#ch6)
- [Agent Safety](#ch7)

---
<!-- Chapter 2-->
<details>

<summary><span id="ch2">Vision Foundation Model Safety </span></summary>

##### Attacks and Defense for ViT
- Patch-fool: Are vision transformers always robust against adversarial perturbations?
    - Yonggan Fu, Shunyao Zhang, Shang Wu, Cheng Wan, Yingyan Celine Lin
    - [ICLR 2022](https://arxiv.org/pdf/2203.08392)

##### Attacks and Defense for SAM


</details>


<!-- Chapter 3-->
<details>

<summary><span id="ch3">Large Language Model Safety</summary>

##### Adversarial Attack

- Bad Characters: Imperceptible NLP Attacks
    - Nicholas Boucher, Ilia Shumailov, Ross Anderson, Nicolas Papernot
    - [S&P 2022](https://arxiv.org/abs/2106.09898)

##### Adversarial Defense

##### Jailbreak Attack

##### Jailbreak Defense

##### Prompt Injection Attacks

##### Prompt Injection Defenses

##### Backdoor Attacks

##### Backdoor Defenses

##### Safety Alignment

##### Energy Latency Attacks

##### Model Extraction Attacks

##### Data Extraction Attacks

</details>

<!-- Chapter 4-->
<details>

<summary><span id="ch4">Vision-Language Pre-training Model Safety</summary>

##### Adversarial Attacks
- Towards Adversarial Attack on Vision-Language Pre-training Models
    - Jiaming Zhang, Qi Yi, Jitao Sang
    - [S&P 2022](https://arxiv.org/abs/2106.09898)

##### Adversarial Defenses

##### Backdoor & Poisoning Attacks

##### Backdoor & Poisoning Defenses


</details>


<!-- Chapter 5-->
<details>

<summary><span id="ch5">Vison Language Model Safety</summary>

##### Adversarial Attacks

##### Jailbreak Attacks

##### Jailbreak Defenses

##### Energy Latency Attacks

##### Prompt Injection Attack

##### Backdoor & Poisoning Attacks

</details>


<!-- Chapter 6-->
<details>

<summary><span id="ch6">Diffusion Models Safety</summary>

##### Adversarial Attacks

##### Jailbreak Attacks

##### Jailbreak Defenses

##### Backdoor Attacks

##### Backdoor Defenses

##### Membership Inference Attacks

##### Data Extraction Attacks

##### Model Extraction Attacks

##### Intellectual Property Protection


</details>


<!-- Chapter 7-->
<details>

<summary><span id="ch7">Agent Safety</summary>

##### LLM Agent

##### VLM Agent

</details>